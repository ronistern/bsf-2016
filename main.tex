\documentclass[12pt]{article}

\usepackage[ruled,vlined,linesnumbered]{algorithm2e}

\usepackage{times}
\usepackage{anysize}
\marginsize{2cm}{2cm}{2cm}{3cm}
%\onehalfspace
%\doublespace
\setlength{\parindent}{0.8cm}
%\setlength{\parskip}{0.2\baselineskip}
%\setlength{\topmargin}{2cm}
%\setlength{\textheight}{25cm}
%\setlength{\textwidth}{14cm}
%\setlength{\oddsidemargin}{2cm}
%\setlength{\evensidemargin}{2cm}
\usepackage{fancyhdr}
\pagestyle{fancy}

\newcommand{\note}[1]{\textbf{\textit{#1}}}
\newcommand{\astar}{A$^*$}
\newcommand{\tuple}[1]{\ensuremath{\left \langle #1 \right \rangle }}

\newtheorem{theorem}{Theorem}
\newtheorem{observation}{Observation}
\newtheorem{corollary}{Corollary}

\linespread{1.3}

\lhead{Data-and-Model Driven Reasoning} \rhead{R. Stern and B. Juba}
\cfoot{\thepage} 
%\cfoot{} 
\pagenumbering{arabic}
%\pagenumbering{Roman}

\begin{document}

%\title{Learning Common Sense Rules Multi-Agent Reasoning with Common}
%\title{Augmenting Model-based Approaches for Diagnosis, Planning, and Plan Recognition with Data}
%\title{Diagnosis, Planning, and Plan Recognition with An Approximate Model and an Abundance of Data}
\title{Data-and-Model Driven Reasoning}
%\note{Need to shorten to 250 words}

\begin{center}
\LARGE{Research Plan}
\end{center}

\section{Scientific and Technological Background}
% 1. From BSF guidelines: A brief description of the subject and the scientific and technological background;

% Reasoning is really important. Example of reasoniong for planning, diagnosis, and plan recognition
{\bf Reasoning} is ``the process of thinking about something in a logical way in order to form a conclusion or judgment'' (Mirriam Webster dictionary), and is commonly attributed as a task that requires some intelligence. Indeed, much of the Artificial Intelligence (AI) research has been devoted to developing methods for reasoning, and effective reasoning is at the heart of classical AI tasks such as planning, diagnosis, and plan recognition. When planning, one needs to reason about possible future actions it may take in order to achieve a desired goal. When diagnosing, one needs to reason about possible explanations to an abnormally behaving systems. Plan recognition can be viewed as a merge of diagnosis and planning: one needs to reason about possible plans an other agent is performing. Indeed, all of these tasks, which are at the core of many AI algorithms and systems, require some form of reasoning.  


%it is the task of identifying the plan an agent is following by observing its behavior. All tasks are commonly studied in the AI literature and are at the core of many AI algorithms and systems. 

%, diagnosis detection and isolation, and recognition. %algorithms that perform tasks such as planning, diagnosing, and others. %an active component in the development of many AI algorithms

%This proposal focuses on three main tasks: automated diagnosis, automated planning, and plan recognition. The first task (diagnosis) is to find identify faulty components in an abnormally behaving system. The second task (planning) is to create a plan for an agent to follow in order to achieve a designated goal. The third task (plan recognition) can be viewed as a merge of diagnosis and planning: it is the task of identifying the plan an agent is following by observing its behavior. All tasks are commonly studied in the AI literature and are at the core of many AI algorithms and systems. 



% The traditional AI approaches are model-based - they assume a model is given
Traditional AI approached these problems using {\em model-based reasoning}, where an underlying model of the world is assumed and is used to find effective solutions. For example, in classical STRIPS planning~\cite{fikes1971strips} the assumed model of the world is  represented by the initial state, actions' preconditions and effects, and the ``frame axioms''~\cite{ghallab2004automated}. 
%This model of the world is used by planning algorithms to search through the space of possible plans. % until finding one that achieves the desired goals. 
In model-based diagnosis (MBD) it assumed that a model of how the diagnosed system is expected to behave is given. In plan recognitions, In plan recognition, the corresponding assumption is that we know the agent's planning capabilities. Indeed, many plan recognition algorithms assume that this is given, e.g., in the form of a plan library that allows identifying all possible plans the agent may be following. % Maybe add here examples of PR algorithms? e.g,. PHATT

%is a prominent approach in the literature for automated diagnosis, which assumes a model of how the diagnosed system is expected to behave is given. Then, MBD algorithms use Truth Maintenance Systems (TMS)~\cite{deKleer1986assumption} or other logical methods to infer from this model possible explanations for an observed abnormal system behavior. % abnormally behaving system. 
%and applies various reasoning techniques to infer from this model and an observed abnormal behavior   is model-based In diagnosis, 
%Truth Maintenance Systems (TMS)~\cite{deKleer1986assumption} and theorem provers are at the heart of classical diagnosis algorithms like the General Diagnosis Engine (GDE)~\cite{de1987diagnosing} and Conflict Directed A* (CDA*)~\cite{williams2007conflict}.\roni{Reading this again, we don't mention here the model at all, only that we reason about something}  


%planning algorithms for classical STRIPS  assume that initial state and the world dynamics (actions preconditiosn and effects) are known and . ~\cite{ghallab2004automated} use a model-based approach which is  manifested by the assumption that the world dynamics are known, and by the well-known ``frame axioms.'' Thinking about it more, the frame axiom 


% Getting models is really hard. But happily enough we got all this data laying around 
As countless applications have discovered, obtaining an accurate model of the world is very difficult. The problems lie in both the {\em scale} and {\em complexity} that such accurate models would require. One of the main hurdles is neatly summarized by the {\em qualification problem}~\cite{mccarthy1987epistemological}: no matter how much we elaborate our formal model, it seems that we can always identify exceptional conditions that the model has failed to capture. Thus, it seems that any models that we can feasibly work with are necessarily only approximations to the true, complex world. Data-driven methods have been proposed as a means to overcome {\em both} of these obstacles~\cite{valiant2000robustLogics}. In particular, in addition to naturally solving the problem of large-scale knowledge acquisition, Valiant argues that data-driven mechanisms may also compensate for the kind of errors that such approximate representations introduce in other parts of a system. Such methods assume that the world is observed and these observations are given as input instead of an accurate model of the underlying world. Then, Machine Learning algorithms are used to learn a model that approximates the world, 
%\note{Roni: it is not clear how data-driven methods overcome this problem. Maybe worth to add here something in the form of "... learn a model that {\em appropriately} approximate the world ..." (i.e, add ``appropriately'') to help make the connection that this kind of approximation does this approximation of the world in a good way, as oppose to manually creating an approximate model}  
in a way that allows us to perform model-based reasoning effectively. 
%and planning. 
In fact, some data-driven approaches even skip this part, and directly learn how to act/diagnose/recognize without generating a complete model of the world~\cite{learningToAct?}.\note{Roni: Brendan, can you fill here the ref. for planning without creating a model? maybe you had in mind some model-free reinforcment learning? if so, I can find a good reference also}
With the growing availability of historical data and computing power, it is reasonable to say that most AI efforts these days are data-driven,
and data-driven algorithms have been proposed for planning~\cite{fern2011first}, diagnosis~\cite{keren2011model,qin2012survey}, and plan recognition~\cite{peng2011helix,tian2016discovering,harpstead2013investigating}. 

% I love this paragraph. Great edits. 


% Data driven is not always great, and model-based is not always great. Here lays the challenge
Clearly, if there is no a-priori knowledge about the world model then data-driven methods are needed. On the other hand, if an accurate, or even an approximate, model of the world is available then it is wasteful to ignore it. %, as it may replace to need for observing much data to reconstruct it. 
Moreover, model-based approaches provide strong theoretical guarantees in terms of completeness and solution quality (e.g., optimality) that can be difficult, if not impossible, to provide without a formal model of the world. % Maybe also talk about a model as being a compact representation of huge amounts of data, and the fact that we do not have inifite data in many case. 
% We aim for the middle ground
% Our goal: when to use which and why
It is the aim of this proposal to study when model-based methods are better than data-driven and vice-versa, and more importantly how to combine them in a principled manner. In particular, we will focus on the {\bf wide spectrum of middle-ground scenarios} between having a {\bf perfect model of the environment without any observations} and having a {\bf large set of observations and no a-prior knowledge} about the world. These kind of model-and-observations scenarios occur frequently in practice and cover a broad range of settings. %, from having both a perfect model and an abundance of observation data to scarce observation data and partial models with limited confidence. 


%where an approximate model of the world is given along with a database of world observations}. 

% The task is challenging - how to combine model and data and outperform current state of the art?
Developing effective algorithms for such model-and-observations settings raises both challenge and opportunities. A key challenge is how to use both sources of information -- (possibly approximate and partial) model and observations? 
We will address this challenge by developing robust, accurate, and effective planning, diagnosis, and plan recognition algorithms that are designed to do so, in a way that will outperform both model-based algorithms and data-driven algorithms that are the state-of-the-art. These data-augmented model-based algorithms are concrete contributions of the proposed research to both academics and practitioners. 

% We want to dig deeper, and develop fundamental theoretical understanding of how model can help data-driven methods 
Beyond practical algorithms that exploit model and observation data, we aim for a deeper challenge: what is the theoretical benefit of having an approximate model over a purely data-driven approach? can it allow us to solve harder problems? 
This theoretical study is intended to uncover the properties of a given model that are most helpful, thus also help direct model building efforts. Relatedly, this will also provide insights into when is it useful to learn a model if we are given data alone, and when it is better to directly learn how to act. 
This follows recent work by PI Juba suggests that from the computational complexity view point it may be preferable in some cases to avoid building a model altogether and rely only on observed data.  \note{Roni: Brendan, can you cite some of your papers that are relevant here?}
%Recent work by PI Juba suggest that in some cases building a model is not beneficial~\cite{}. \note{Brendan, I am not sure I am describing correct what you've done. Please verify?} 
%Third, even if such an approximate model is available, it may still be preferable to avoid using it and only rely on the observed data, from the computational complexity view point.


% We will focus on planning, diagnosis, and plan recognition. We are experts in these problems, and are also complementary in our expertiese, so please give us funding!
While these challenges are very  general, we will focus on the specific, yet highly important, tasks of planning, diagnosis, and plan recognition. PI Stern has past experience in developing state-of-the-art planning~\cite{felner2004pha,sharon2013increasing,sharon2015conflict,goldenberg2014enhanced,stern2014potential,maliah2016collaborative}, diagnosis~\cite{stern2012exploring,stern2014model,stern2014hierarchical}, and plan recognition~\cite{mirsky2016sequential} algorithms. 
In parallel, PI Juba's recent work laid the theoretical foundation for learning and using common-sense reasoning for abduction and diagnosis~\cite{yourAAAI'16paper} as well planning~\cite{yourPOMPDJMLRpaper}. \note{Roni: Brendan, can you put the appropriate citation of your papers in the references in the previous sentence? I think I know the right ones but not 100\% sure.}
%PI Juba's recent work lay the theoretical foundation for our main approaches to meet these challenges~\cite{}, and have exactly studies their application in planning~\cite{} and abductive reasoning~\cite{} (where diagnosis is a special case of). 
%\note{Roni: I'm starting to fill the bib file with my refs. Brendan - TODO-level2: fill your references in the bib file.}
%Notable, most of the PI Stern's work was empirical while most of PI Juba's work has been theoretical, and thus their collaboration in the proposed research is key to its success, utilizing their complementary expertise.  
Thus, the proposed research is especially suited for the complimentary expertise of the PIs. %. PI Stern's work proposed several practical diagnosis~\cite{}, planning~\cite{}, and plan recognition algorithms~\cite{}. 
Moreover, each of the PIs has preliminary work that demonstrate the potential of a model-and-observations approach for planning~\cite{stern2011probably,stern2012exploring,juba2016jmlr} and diagnosis~\cite{elmishali2016dataAugmented}.
\note{Brendan: which of your works can fit here? maybe the NDDS one?}
%% Roni: unfortunately the NDSS paper didn't end up featuring any of the new algorithms. It turns out that the data-oblivious program analysis my co-authors had used for the image filtering application was tight enough that when we simply checked the filter on a test set, it had no false positives and hence we could verify it had PAC validity. The contribution of the paper was really about how to collect the data, which is nontrivial since users' web-surfing is sensitive. I haven't been able to get the co-authors on board with a follow-up study of some more complex data types that might require more interesting algorithms. But I am including the JMLR paper since one key part of that work was to use *both* explicitly given frame axioms together with a learned action model. (The frame axioms were formulated using naf so that they don't require knowledge of the action model to state.) The work could naturally incorporate additional explicit rules.

%\subsection{Background on Automated Planning}
%TODO
%\subsection{Background on Model-based Diagnosis (MBD)}
%TODO
%\subsection{Background on Plan Recognition}
%TODO
%\subsection{Background on PAC Semantic}
%TODO
%\subsection{Background on Learning to Act?}
%TODO
%\subsection{Background on Data-Augemented Reasoning}
%TODO: Talk here about prior work that combined model-based and data-driven approaches.  This will include our works, but also, of course, others. In particular, I think that model-based reenforcement learning works need to be mentioned. 


\section{Objectives and Significance}
%2. From BSF guidelines: Objectives and significance of the research

TODO (MORE OR LESS RESTATE WHAT WAS ABOVE IN A CONCISER WAY)

%[[From e-mails]] For our own work, even if we can't nail down precisely when our algorithms work well, we will still strive to obtain some partial understanding of when and why the approach works, as is being done for SAT solvers.


% Broader significance

% Different settings: no model, some model, reliable model
The contributions of the proposed research go far beyond creating better algorithms for diagnosis, planning, and plan recognition.  By studying and understanding the effect of having an approximate model on the theoretical limits of what can be learned from data, 
and what needs to be supplied by the approximate model, one can impact the efforts used to generate such approximate models in a more informed way. For example, if some aspect of the world is especially difficult to learn, then it makes sense to divert expert efforts in modelling it, while if other parts are easier to learn then expert costs can be saved. Since modeling the worlds is notoriously difficult, choosing what not to model is key in practical applications of AI. 
Moreover, we show that one may actually choose to ignore a given model 
if sufficient data is available, in order to speedup the reasoning process. 



%\section{Detailed Description of the Proposed Research}
%3. From BSF guidelines: Comprehensive description of the methodology and plan of operation, including the respective roles of the Israeli and American principal investigators;
\section{Methodology and Plan of Operation}
\label{sec:methodology}


% Key setting: we have a model and observations
The main setting the proposed research will focus on is that we are given two types of data as input: 
a {\em model} and a set of {\em observations}. The model represents some prior knowledge about the rules that govern the behavior of the world. The observations represents data collected about some  interactions with the world in the past. 
In some sense, the observations represents some knowledge about {\em how the world behaved in the past} and the model represents knowledge about {\em how the world is expected to behave in the future}. What exactly does these model and observations comprise depends on the reasoning task at hand. In the proposed research we focus on reasoning for three classical AI tasks: planning, diagnosis, and plan recognition. %We describe first our proposed research on model-and-data reasoning for the planning tasks. 



\subsection{Model-and-Observations Reasoning for Planning}


% What is the observations and the domain in planning
In planning, the task is to create a plan for an agent to follow in order to achieve a designated goal. A model in the planning context is any information the agent has about the current state and how its actions impact the world. %In planning this is usually referred to as the {\em domain description}. 
For example, in classical planning~\cite{fikes1971strips}, a model can be a description of the pre-conditions and effects of each action given in PDDL (the Planning Domain Description Language). In more involved planning models such as Markov Decision Problems (MDP) and Partially Observable MDPs, the model can also include the transition and observation functions that capture knowledge about the stochatic nature of the world. 
%[[Roni: I think that to make things simpler lets focus on classical planning and then talk about how to generalize to MDP/POMDP



Observations in the context of planning are {\em trajectories} of actions performed by the agent to get from one state to another. These trajectories as sequences of the form $\tuple{ s_1, a_1, s_2, a_2, \ldots}$, where $s_i$ is a state, $a_i$ is the action performed when at state $s_i$, and $s_{i+1}$ is the state the agent has reached after performing action $a_i$ at state $s_i$. In the most minimal sense observing a trajectory simply reveals that it was possible to get from state $s_i$ to state $s_{i+1}$ by applying action $a_i$. % Maybe talk about partial observablity?


%of state and actions pairs, representing a state
%and some (perhaps partial or inaccurate) view of the states reached by that agent when performing them. 


% In the case of a complete model, we can find solutions, even optimal ones, but it will take forever. Mabye we can use a data-driven approach to overcome this?
\subsubsection{Planning with a Complete Model and Observation}



% Sometimes we have complete models, so we can plan. But it is still so hard!
In some cases, a complete model of the world may provide a sufficient form of abstraction so that a plans generate for it can be used in practice~\cite{citeSomeApplicationsOfPDDLPlanning}. Indeed, much work has been devoted throughout the years on solving classical planning problems~\cite{someManyPlanningPapers}. A key challenge in such cases is the complexity of finding a plan, which is PSPACE hard in general~\cite{bylander1994computational}. 




% We will use observations to help us plan faster!
We propose to study two ways in which observations -- i.e., trajectories of actions performed by the agent in the past -- can help to meet this complexity challenge. The first is to use the given observations to evluate how different planning algorithms and heuristics perform, and adapt the planning algorithms accordingly. The second is to learn from the given observations special cases of the general planning problem that can be solved efficiently in the domain at hand. We detail both  approaches below. 



% Related work - learning is not new in planning
Learning from trajectories how to plan more efficiently is not novel. 
One particular approach is to use observed trajectories to learn accurate heuristic functions that estimate the distance to a goal better than traditional model-based heuristic functions. For example, Yoon et al.~\cite{yoon2006learning} proposed a method to learn from observed trajectories how to improve the FastForward heuristic function by considering various features of the relaxed plan it is based on. 
Samadi et al.~\cite{samadi2008learning} used an Artificial Neural Network to learn heuristic functions for several search benchmarks and Jabbari Arfaee et al.~\cite{arfaee2011learning} proposed a bootstrapping techniques for doing so for larger state spaces. The Learning as search optimization (LaSO) approach uses learning in a different way, trying to learn in Beam Search which states are ``good'' (should stay on the beam) and which are ``bad'', instead of trying to learn the true distance to a goal~\cite{xu2007discriminative}. This was applied successfully to Beam search. Perhaps most closely related work is that of Phillips et al.~\cite{phillips2012graphs} proposed a bounded-suboptimal search algorithm that biases the search towards directions that are part of a given set of observed trajectories. All the above highlights the importance that the planning community gives to  finding novel and effective ways to incorporate knowledge about past data -- e.g., trajectories -- in the classical planning process. In fact, there is even a recently added track in the international planning competition is specifically dedicated to the combination of learning and plannning~\cite{fern2011first}. 


% Too weak. Need a stronger differential discussion



%Preliminary work by PI Stern proposed a framework called Probably Approximately Correct Heuristic Search (PAC Search) that allows using knowledge about optimal solutions of similar problems to obtain a probabilistic solution quality guarantees~\cite{stern2011probably,stern2012search}. 
%That work, which built on earlier work by Ernandes and Gori~\cite{ernandes2004likely}, used statistics gathered from these optimal solutions to create for each generated state an estimate of the likelihood that it will improve on the incumbent solution. These likelihood estimates are used when a goal is found to compute the likelihood that it is optimal or approximately optimal. 
%Knowing the likelihood that a given solution is approximately optimal has important applications. First, one can use such estimates to decide intelligently when a sufficient plan has been found and further planning is not needed. Second, one can report to the user that issued 
%This estimate is derived from mining past optimal solutions to similar problems in the same domain. Thus, when a goal is found, one can compute the likelihood that it is optimal or approximately optimal. Beyond the theoretical elegance of having such guarantees, they can also be used to decide when a sufficient plan has been found and further planning is not needed.


% Since planning and learning work so well together, we need to better understand this relationship
Encouraged by the recent success stories of learning for planning, 
we aim to provide a theoretical framework for incorporating knowledge from observed trajectories in the process of model-based planning. Such a framework is sourly needed in order to understand the extent to which trajectories can help to improve planning, as well as to understand how using learning-based heuristic affect the properties of the search algorithms that uses them. 


% Option #1: PAC Search: what to do with trajectories? how many are useful?
{\bf Probably Approximately Correct Heuristic Search.} 
% Approximately optimal
One particular theoretical framework we propose to develop is the Probably Approximately Correct Heuristic Search (PAC Search), which is intended to allow probabilistic solution quality guarantees even for deterministic planning~\cite{stern2011probably,stern2012search}. 
To explain this framework, which was suggested in a preliminary work by PI Stern~\cite{stern2011probably,stern2012search}, we provide the following brief background. 
Heuristic search is a fundamental problem solving technique that is commonly used to solve planning problems. Heuristic search algorithms use heuristics to efficiently explore a usually very large space of possible trajectories, aiming to find a trajectory that forms a sufficient plan. What regards as a sufficient plan depends on the requirements set by the user: in some cases only optimal -- lowest cost -- plans are sufficient while in other cases sub-optimal plans are also acceptable. Since finding optimal plans can be very difficult a common compromise is to require solutions that are {\em approximately optimal}, in the sense that a solution is sufficient if its cost is no larger than $1+\epsilon$ times the cost of the optimal solution, where $\epsilon$ is a parameter set by the user. Such algorithms are called {\em bounded-suboptimal search algorithms}. 


% Approximately optimal sucks
To date, search algorithm that return approximately optimal are severely limited in that they obtain their solution quality guarantee (i.e., at most $1+\epsilon$ of optimal) by consider an {\em admissible} heuristic function. Admissible heuristic function are heuristic function that provide a lower bound on the cost of reaching the goal. By construction, such heuristic function are biased and tend to be inaccurate. Consequently, bounded suboptimal search algorithm often continue the search for better plans even though their incumbent plan (the best plan found so far) is already approximately optimal. In addition, they are limited in their ability to learn from observed trajectories~\cite{ees,egraphs}.

% PAC is so great. It will make world peace. 
The PAC search framework we propose to develop will allow planning algorithms based on heuristic search to fully exploit past experience and observations. In PAC search, which builds on earlier work by Ernandes and Gori~\cite{ernandes2004likely}, each generated state is associagted with an estimate of the likelihood that it will improve on the incumbent solution. This estimate is derived from mining past optimal solutions to similar problems in the same domain. Thus, when a goal is found, one can compute the likelihood that it is optimal or approximately optimal. Beyond the theoretical elegance of having such guarantees, they allow more informed decision making when planning. In particular, one can identify when a sufficient plan has been found earlier than when only using an admissible heuristic, thus significantly speeding up the search. Moreover, probabilistic solution quality guarantees 
provide a more accurate view of the incumbent solution than the current worst-case quality estimate obtained when using admissible heuristics.  


%In that preliminary study the PAC Search framework was only used to provide a better sense of the incumbent solution in an anytime search. 

% But there are so many challenges, you must give us money to study it
While PI Stern's initial study of PAC search showed promising results~\cite{stern2011probably,stern2012search}, there are still many challenges that prevent it from gaining significant adoption and impact. First, current PAC search algorithms require trajectories that are optimal plans. This limits the applicability of PAC search, since finding optimal plans can be very difficult. We will study several ways to meet this challenge. One approach is it to gather statistics on smaller problems which can be solved optimally and extrapolate on larger problems. Another approach is to estimate the suboptimality of observed trajectories, e.g., using solution cost prediction algorithm, such as those developed by PI Stern~\cite{}. 



% Second challenge - sample set
A second challenge to the wide-spread adoption of PAC search, is that there is no clear guideline forhow many trajectories are needed to learn meaningful information about the likelihood of a state to lead to a goal. This is a manifestation of the classical sample set complexity problem that is often studied in the Machine Learning literature. Indeed, PI Juba has vast experience in performing such analysis and is thus the collaboration between the PIs is especially suitable to address these challenges. 



{\bf }
TODO: Something about using trajectories to create macros in a smart way

{\bf }
TODO: Something about imperfect model







\subsection{Model-and-Observations Reasoning for Diagnosis}
% What is diagnosis. It is important
{\em Automated diagnosis} (DX) is the second reasoning task for which we investigate how to exploit both model and observations. The DX task is to find plausible explanations to an observed abnormally behaving system. Such explanations -- also referred to as {\em diagnoses} -- usually point to one or more components of the observed system that may be faulty. 
Hardware and software systems these days are growing in complexity, and thus effective DX algorithms are crucial. 


% Approaches for DX
Several approaches have been proposed to solve the diagnosis problem. Two prominent approaches are {\em model-based} and {\em data-driven}. In both approaches some observations of the current behavior are given. In Model-Based Diagnosis (MBD), we are also given a model of the diagnosed system and inference techniques are used to infer diagnoses 


that includes 
a diagnosis problem is defined by the tuple $\tuple{SD, COMPS, OBS}$ 
where $SD$ is a model of the diagnosed system, 
$COMPS$ is a set of components, 
and $OBS$ is a set of observations. 
The model $SD$ is assumed to describe how every component is expected to behave when functioning properly, and, in some cases, $SD$ also describes how it functions abnormally. 
Importantly, $OBS$ usually refers to the observations available on the systems current behavior. MBD algorithms use $SD$ and $OBS$ together to infer diagnoses. 
MBD has been successfully applied in a range of domains~\cite{williams96,struss2003model,wotawa2002model}, and lays on solid theoretical grounds~\cite{de1987diagnosing,reiter1987theory}. MBD has two key limitations. First, it requires a model of the system, which is expensive to create and is often inaccurate. Second, solving a diagnosis problem with MBD is, in terms of computational complexity, intractable~\cite{bylander1991computational}. 

% Data driven is awsome, but dont' give guarantees and is bad for multiple faults.
Data-driven diagnosis is an alternative to MBD in which no model of the diagnosed system is assumed. A data-driven diagnosis algorithm accepts as input a large set of such past observations. Importantly, these observations differ from the MBD observations ($OBS$) described above 
in that they represent observations made in the past, and each observation is paired with the diagnosis that matchs it. With these observations, data-driven methods employ statistical techniques to learn an efficient function, e.g., a decision tree, that will map future observations to their correct diagnosis. This function is usually very fast, and thus using a data-driven approach for diagnosing is usually much faster than MBD. 
Data-driven diagnosis lacks, however, formal guarantees to its correctness and performs poorly for observations with multiple faults~\cite{keren2011model}. 



%and diagnoses are found much faster, in genral. 
We propose to develop theory and algorithms that exploit both model -- to the extent that it is available -- and this data about past observations, in an effort to enjoy the pros of both approaches. Below we describe the concrete approaches we will follow in this line of research.

\subsubsection{Diagnosis with a Complete Model and Past Observations}

TODO: Add something here.

{\bf Data-Driven Prioritization.}\\
% The problem: too much diagnoses
Most MBD algorithms are consistency-based, in the sense that they aim to return every assumption about which component is faulty that is consistent with the system model and observations. \note{Maybe we want to add a simple example?} 
Unfortunately, there can be many consistent diagnoses for a given set of observations, thus providing poor fault isolation. Therefore, much effort has been devoted to focusing only on the diagnoses that are estimated to be more likly to be true. For example, it is common in the MBD literature to focus on finding only {\em minimal cardinality} diagnoses, which are diagnoses that assume the minimal number faulty components. However, as shown in PI Stern's prior work, the number of minimal cardinality diagnoses can be very large, even in standard MBD benchmarks~\cite{stern2015many}. 


% Let's use data to prioritize
We propose to employ a data-driven approach to address this challenge. 
Learning algorithms can be used to generate a function that maps observations, and various model properties, to the components that are more likely to be part of the correct diagnosis. This follows an underlying assumption that components there were faulty in the future tend to fail again. This learned function is used in the diagnostic process to prioritize the consistent diagnoses. So, the resulting algorithm will be a combination of MBD algorithm for generating diagnoses and data-driven method. This hybrid model-and-data approach for MBD is very general, and our preliminary results on software diagnosis~\cite{elmishali2016data} show promising results. 

\note{I feel that we need more here. Maybe something about uncovering the theory behind this combination of data and model?}


{\bf Learning Plausible Diagnoses.}\\
Similar to planning, in diagnosis also there are special cases that can be solved in tractable time. PI Juba's recent work proposed a theoretical framework for learning to identify such  special cases and how to diagnose them efficiently.\note{Brendan TODO-level1: maybe you can fill in the gap here?}



Learn conditions on sensors taht yield a small set of possbile diagnoses
(see AAAI paper)


{\bf Incompelte model?}


BN 
CPTs




\subsection{Model-and-Observations Reasoning for Plan Recognition}
The last reasoning task we investigate is plan recognition. In plan recognition (PR), the task is to identify the plan being followed by an agent by observing its behavior. PR can be viewed as a generalization of the aforementioned diagnosis task~\cite{mclaraith}, where the plan being followed corresponds to the behavior of the faulty components. 
Some form of PR is needed in the development of intelligent user interfaces~\cite{} and human-robot interaction, and in general as part of an effective collaboration~\cite{todo}. 

Slightly more formal, in PR we are given a set of observations 

PR is a fundamental task in AI and has been studied in the lite

In PR the model is the possible plans the observed agent may be following. This can be given as a set of plans, or in a more compact way by defining the planning domain that the observed agent maintains when planning. For example, some work on PR assumed that a plan library is given in the form of a context free grammar, and that the agent uses this plan library to construct a heirarchical plan~\cite{}. In other cases, a STRIPS-like domain definition is given to the PR algorithm as the model. 

....






\subsection{Evaluation}

We will take standard benchmarks for each of these problems and will add ``noise'' to the model. Then, compare model-based methods that only reason about the noisy model, data-driven methods that attempt to directly answer the quetion (not sure this fits for planning, but it does for diagnosis and plan recognition), data-driven methods that learn an model and then apply reasoning, 
and then some new methods by us that integrate all these things nicely. 


%4. From BSF guidelines: Risk analysis and alternative paths that will be followed if the suggested research plan fails (only in those fields in which it is relevant);
\section{Risk Analysis and Alternative Plans}


\section{Collaboration between the Principal Investigators}
TBD

%5. From BSF guidelines: An account of available U.S. and Israeli resources, including all personnel and equipment relevant to the research;
\section{Available U.S. and Israeli Resources}






\pagebreak
\bibliographystyle{plain}
\bibliography{references}

\end{document}

